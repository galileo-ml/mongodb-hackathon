"""Mock metadata service that simulates real-time speaker diarization events via SSE."""

import asyncio
import logging
import random
from datetime import datetime
from uuid import uuid4

from fastapi import FastAPI
from sse_starlette.sse import EventSourceResponse

from models import ConversationEvent

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger("mock_metadata")

app = FastAPI(title="Mock Metadata Service - Dementia Care")

# Mock conversation data for dementia care scenario
MOCK_CONVERSATIONS = {
    "person_001": [  # Sarah (daughter)
        "Hi dad, how are you feeling today?",
        "I got that promotion at work I mentioned!",
        "The kids are so excited to visit you next weekend.",
        "Do you remember we talked about the garden last time?",
        "I'll bring your favorite cookies when I visit.",
        "How has your week been?",
    ],
    "person_002": [  # Michael (son)
        "Hey dad, I brought some groceries for you.",
        "My car is finally fixed after that issue.",
        "I'm planning a camping trip next month.",
        "Want to watch the game together this Sunday?",
        "How are you feeling today?",
        "The weather has been great for walking.",
    ],
    "person_003": [  # Robert (friend)
        "Have you finished that mystery novel yet?",
        "Book club is meeting next Tuesday.",
        "Remember when we used to play chess in college?",
        "I found an old photo of us from graduation.",
        "The new library downtown is wonderful.",
        "What have you been reading lately?",
    ]
}

async def generate_conversation_events():
    """Generate mock conversation events with realistic timing and conversation flow."""
    event_count = 0

    while True:
        try:
            # Simulate variable timing between utterances (3-7 seconds)
            await asyncio.sleep(random.uniform(3.0, 7.0))

            # Pick a person
            person_id = random.choice(["person_001", "person_002", "person_003"])

            # Pick appropriate text for this person
            text = random.choice(MOCK_CONVERSATIONS.get(person_id, ["Hello"]))

            event = ConversationEvent(
                person_id=person_id,
                text=text,
                timestamp=datetime.utcnow(),
                confidence=random.uniform(0.85, 0.99)
                # Note: event_id and conversation_id are optional and will be generated by inference service
            )

            event_count += 1
            logger.info(f"Event #{event_count}: {event.person_id} - {event.text[:40]}...")

            yield {
                "event": "conversation",
                "data": event.model_dump_json(),
            }

        except asyncio.CancelledError:
            logger.info("Stream cancelled")
            break
        except Exception as e:
            logger.error(f"Error generating event: {e}")
            break


@app.get("/stream/conversation")
async def stream_conversation():
    """SSE endpoint that streams mock conversation events."""
    logger.info("New client connected to conversation stream")
    return EventSourceResponse(generate_conversation_events())


@app.get("/health")
async def health():
    """Health check endpoint."""
    return {
        "status": "ok",
        "service": "mock_metadata_service"
    }


@app.get("/")
async def root():
    """Root endpoint with service info."""
    return {
        "service": "mock_metadata_service",
        "version": "0.2.0",
        "focus": "dementia_care",
        "endpoints": {
            "conversation_stream": "/stream/conversation",
            "health": "/health"
        }
    }


if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8001, log_level="info")
